[
  {
    "path": "posts/2023-02-15-design-a-music-album-database-using-MySQL/",
    "title": "Design a Music Database using MySQL",
    "description": "Using MySQL to design a database and perform a descriptive analysis on music database.",
    "author": [
      {
        "name": "Miftahul Hadi",
        "url": {
          "https://www.linkedin.com/in/miftahulhadii": {}
        }
      }
    ],
    "date": "2023-02-15",
    "categories": [
      "SQL",
      "ETL"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nPreparation\r\nDesign a Database\r\nSQL Query Problem\r\nAppendix\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nHello and welcome to the MySQL personal project!\r\nFig. 1. MySQL Database.In this post, I will design a database about music albums, bands, and songs. After database is created, I inserting a data on each table. Then, I address some of the SQL Query problems to get better understanding of the information.\r\nPreparation\r\nTools\r\nTo make this project completed, I use SQL for cleaning and analysis. There are many SQL editors where you can design and manipulate a database. For this particular project, I used MySQL Workbench.\r\nDataset\r\nThe dataset I used in this project is open-source data without any PII (Personally Identifiable Information). I obtain from my favorite web development skills YouTuber, WebDevSimplified, and you can watch all of their videos hereThis music dataset contains\r\nThis music dataset contains detailed information about bands, albums, and songs. This includes three tables that have more than 180 rows. Because the value is being inserted into the table, this dataset is ideal for designing a database from scratch.\r\nDesign a Database\r\nCreate a database\r\nTo begin, I must add and use a new database named record_company to our MySQL schema.\r\n\r\nCREATE DATABASE record_company;\r\nUSE record_company;\r\n\r\nBecause the record_company database is already in use, it will appear in the schema with bold text.\r\nFig. 2. New database named record_company.Design a table\r\nAfter creating a database named record_company, we try to add a few tables including bands, albums, and songs tables. Here are the steps:\r\nBands table\r\nNext, I add the bands table to our record_company database. This includes three columns:\r\nid to uniquely identify band data input,\r\nname for the band’s name, and\r\nmake id our table identifier or Primary Key.\r\n\r\n\r\nCREATE TABLE bands (\r\n  id INT NOT NULL AUTO_INCREMENT,\r\n  name VARCHAR(255) NOT NULL,\r\n  PRIMARY KEY (id)\r\n);\r\n\r\nAlbums table\r\nAfter that, I add an albums table including information on albums they have produced. This includes four columns:\r\nid to uniquely identify albums data input,\r\nname for the album’s name,\r\nrelease_year for the album’s year released,\r\nband_id for uniquely identifying the band (same as id on bands table), and\r\nMake the id of the albums table the primary key.\r\nConnect band_id column from albums table to the id column from bands table.\r\n\r\n\r\nCREATE TABLE albums (\r\n  id INT NOT NULL AUTO_INCREMENT,\r\n  name VARCHAR(255) NOT NULL,\r\n  release_year INT,\r\n  band_id INT NOT NULL,\r\n  PRIMARY KEY (id),\r\n  FOREIGN KEY (band_id) REFERENCES bands(id)\r\n);\r\n\r\nSongs table\r\nLastly, add songs table including information on songs they have produced. This includes four columns:\r\nid to uniquely identify songs data input,\r\nname for the songs’ name,\r\nlength for the duration of the song,\r\nalbum_id for uniquely identifying the album (same as id on albums table).\r\nMake the id of the songs table the primary key.\r\nConnect album_id column from songs table to the id column from albums table.\r\n\r\n\r\nCREATE TABLE songs (\r\n    id INT NOT NULL AUTO_INCREMENT,\r\n    name VARCHAR(255) NOT NULL,\r\n    length FLOAT NOT NULL,\r\n    album_id INT NOT NULL,\r\n    PRIMARY KEY (id),\r\n    FOREIGN KEY (album_id) REFERENCES albums(id)\r\n);\r\n\r\nBecause I already add three tables, it will appear in the schema like this.\r\nFig. 3. A three tables appear in record_company database.Insert the value in the table.\r\nAfter designing a few tables in the database, I insert a number of values into the table. Here, I will use an INSERT INTO function into bands table.\r\n\r\nINSERT INTO bands(id,name) VALUES (1,'Seventh Wonder');\r\nINSERT INTO bands(id,name) VALUES (2,'Metallica');\r\nINSERT INTO bands(id,name) VALUES (3,'The Ocean');\r\nINSERT INTO bands(id,name) VALUES (4,'Within Temptation');\r\nINSERT INTO bands(id,name) VALUES (5,'Death');\r\nINSERT INTO bands(id,name) VALUES (6,'Van Canto');\r\nINSERT INTO bands(id,name) VALUES (7,'Dream Theater');\r\n\r\nBecause the dataset has a large number of rows, I will include another table in this file thanks to WebDevSimplified.\r\nSQL Query Problem\r\nIn this section, I will use some of SQL Query to answer a few question. This will helps us to get better understanding of the dataset.\r\nHow many bands in this dataset?\r\nQuery\r\n\r\nSELECT bands.name AS 'Band Name'\r\nFROM bands;\r\n\r\nHere are all the bands that included in this dataset.\r\nFig. 4. All the bands included.Which is the oldest album?\r\nWhich bands have released at least one album?\r\nWhich bands that have no album?\r\nLongest album duration?\r\nUpdate the album data with no release year\r\nInsert my favourite band and their albums\r\nDelete the band and album you added before\r\nAverage length of all songs\r\nWhich song on each album is the longest?\r\nGet the number of songs for each band\r\nAppendix\r\nWebDevSimplified [YouTube, GitHub]\r\nKaggle Full Script\r\n\r\n\r\n\r\n",
    "preview": "https://linkoficial.com.br/wp-content/uploads/2017/10/mysql-logo.png",
    "last_modified": "2023-02-20T18:57:18+07:00",
    "input_file": "design-a-music-album-database-using-MySQL.knit.md"
  },
  {
    "path": "posts/2023-01-29-bike-share-analysis-using-r/",
    "title": "Bike Share Marketing Campaigns Analysis using R",
    "description": "Investigate a bike-share company's marketing campaigns to create a new one that is more profitable for the company.",
    "author": [
      {
        "name": "Miftahul Hadi",
        "url": {}
      }
    ],
    "date": "2023-01-29",
    "categories": [
      "R",
      "ETL",
      "Marketing Analysis",
      "Data Visualization"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nPreparation\r\nProcessing the Data\r\nAnalysis\r\nRecommendation\r\nAppendix\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nScenario\r\nWelcome to the Cyclistic bike-share analysis case study!\r\nFig. 1. Bike-share stationIn this case study, I am here as a junior data analyst working in the marketing team at Cyclistic, a fictional bike-share company in Chicago. Lily Moreno, the marketing director, believes that the company’s future success depends on maximizing the number of annual memberships.\r\nTo ride a Cylcistic bike, you can unlock it from one station and return it to any other station in the system. There are a few pricing plans to purchase:\r\nSingle-ride passes\r\nFull-day passes\r\nAnnual memberships\r\nCustomers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members.\r\nOur task here is to understand how casual riders and annual members use Cyclistic bikes differently. The marketing team will design a new marketing strategy from these insights to convert casual riders into annual members. But, Cyclistic executives must approve your recommendations with compelling data insights and visualization.\r\nMore about company’s details\r\nIn 2016, Cyclistic launched a successful bike-share offering. Since then, the program has grown to a fleet of 5,824 bicycles that are geo-tracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system at any time.\r\nUntil now, Cyclistic’s marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members.\r\nCyclistic’s finance analysts have concluded that annual members are much more profitable than casual riders. Although the pricing flexibility helps Cyclistic attract more customers, Moreno believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign targeting all-new customers, Moreno believes there is a good chance to convert casual riders into members. She notes that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs.\r\nMoreno has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the marketing analyst team needs to better understand how annual members and casual riders differ, why casual riders would buy a membership, and how digital media could affect their marketing tactics. Moreno and her team are interested in analyzing the Cyclistic historical bike trip data to identify trends.\r\nObjectives\r\nIdentify how casual and members riders use Cyclistic bikes differently to maximize the number of annual memberships.\r\nPreparation\r\nHere are a few tools used in this analysis:\r\nRStudio\r\nThe library used in R: tidyverse, ggplot2, lubridate, readxl\r\nDataset\r\nCyclistic’s historical trip data in 2022\r\nThe license has been made available by Motivate International Inc.\r\n\r\nProcessing the Data\r\nHere’s a step by step of processing raw data to be prepared for analysis:\r\nImport your data\r\nTo connect the data to the R environment, the step as follows:\r\nFirst, download the previous 12 months’ Cyclistic trips in .csv format.\r\nSecond, convert the data from .csv to xlsx format. Store it in a new folder (e.g. “~/bike-project/xlsx-version”)\r\nNext, load the library used in this analysis and set the main directory where the data is stored.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(ggplot2)\r\nlibrary(lubridate)\r\nlibrary(readxl)\r\n#setwd(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version\")\r\n#setwd is not used because of web development circumstances\r\n\r\n\r\nUsing the readxl library, load the data and give the name each month.\r\n\r\n\r\nm1_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202201-divvy-tripdata.xlsx\")\r\nm2_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202202-divvy-tripdata.xlsx\")\r\nm3_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202203-divvy-tripdata.xlsx\")\r\nm4_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202204-divvy-tripdata.xlsx\")\r\nm5_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202205-divvy-tripdata.xlsx\")\r\nm6_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202206-divvy-tripdata.xlsx\")\r\nm7_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202207-divvy-tripdata.xlsx\")\r\nm8_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202208-divvy-tripdata.xlsx\")\r\nm9_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202209-divvy-tripdata.xlsx\")\r\nm10_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202210-divvy-tripdata.xlsx\")\r\nm11_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202211-divvy-tripdata.xlsx\")\r\nm12_2022 <- read_xlsx(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version/202212-divvy-tripdata.xlsx\")\r\n\r\n#(\"C:/Users/LENOVO/Documents/bike-project/xlsx-version\") still used because of web development circumstances\r\n\r\n\r\nMake columns consistent and merge into a single data frame\r\nTo make columns ready to analysis, here’s the step:\r\nFirstly, check the columns name of each months trips data.\r\n\r\n\r\ncolnames(m1_2022)\r\ncolnames(m2_2022)\r\ncolnames(m3_2022)\r\ncolnames(m4_2022)\r\ncolnames(m5_2022)\r\ncolnames(m6_2022)\r\ncolnames(m7_2022)\r\ncolnames(m8_2022)\r\ncolnames(m9_2022)\r\ncolnames(m10_2022)\r\ncolnames(m11_2022)\r\ncolnames(m12_2022)\r\n\r\n\r\nAfter that, check the data types.\r\n\r\n\r\nstr(m1_2022)\r\nstr(m2_2022)\r\nstr(m3_2022)\r\nstr(m4_2022)\r\nstr(m5_2022)\r\nstr(m6_2022)\r\nstr(m7_2022)\r\nstr(m8_2022)\r\nstr(m9_2022)\r\nstr(m10_2022)\r\nstr(m11_2022)\r\nstr(m12_2022)\r\n\r\n\r\nChange the data types if you find a column that differs from the rest of the columns in another file.\r\nLastly, combine all sheets into one single data frame and named it all_trips.\r\n\r\n\r\nall_trips <- bind_rows(m1_2022, m2_2022, m3_2022, \r\n                       m4_2022, m5_2022, m6_2022, \r\n                       m7_2022, m8_2022, m9_2022, \r\n                       m10_2022, m11_2022, m12_2022)\r\n\r\n\r\nClean the data\r\nAfter combine all month trips data, we can clean them to be ready to analysis. Here’s the step:\r\nRemove a few unused column.\r\n\r\n\r\nall_trips <- all_trips %>%\r\n  select(-c(start_lat, start_lng, end_lat, end_lng))\r\n\r\n\r\nCheck the data frame attributes.\r\n\r\n\r\ncolnames(all_trips)   #list of column names\r\nnrow(all_trips)       #total row\r\ndim(all_trips)        #total dimension\r\nhead(all_trips)       #view first 6 rows\r\nstr(all_trips)        #see list of data types\r\nsummary(all_trips)    #statistical summary\r\n\r\n\r\nCheck if there’s any problem in memberships column\r\n\r\n\r\nunique(all_trips$member_casual) #for unique value\r\n\r\n[1] \"casual\" \"member\" NA      \r\n\r\ntable(all_trips$member_casual)  #total unique value\r\n\r\n\r\n casual  member \r\n2322031 3345683 \r\n\r\nAs we know, memberships program in Cyclistic only have two, casual and members riders. So, if there’s any dualism value (e.g. subscriber instead of members), change the value.\r\n\r\n\r\nall_trips <- all_trips %>% \r\nmutate(member_casual = recode(member_casual, \"Subscriber\" = \"member\", \"Customer\" = \"casual\"))\r\n\r\n\r\nAdd columns that list the date, month, day, and year of each ride.\r\n\r\n\r\nall_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd\r\nall_trips$month <- format(as.Date(all_trips$date), \"%m\")\r\nall_trips$day <- format(as.Date(all_trips$date), \"%d\")\r\nall_trips$year <- format(as.Date(all_trips$date), \"%Y\")\r\nall_trips$day_of_week <- format(as.Date(all_trips$date), \"%A\")\r\n\r\n\r\nMake a new column that shows different time of started ride to ended ride.\r\n\r\n\r\nall_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)\r\n\r\n\r\nAfter creating a new column, inspect the columns data types to make sure.\r\n\r\n\r\nstr(all_trips)\r\n\r\n\r\nAfter checking the data types, we found that ride_length column still not in numeric types.\r\n\r\n\r\nis.numeric(all_trips$ride_length) #to check if the ride length was in number/factor\r\n\r\n[1] FALSE\r\n\r\nall_trips$ride_length <- as.numeric(all_trips$ride_length)\r\nis.numeric(all_trips$ride_length)\r\n\r\n[1] TRUE\r\n\r\nWe found that there is two ride_length column. Remove bad data to make it consistent.\r\n\r\n\r\nall_trips <- select(all_trips, -c(ride_of_length))\r\n\r\n\r\nAfter creating a ride length column, there’s some data that peculiar (minus ride length). Remove it using subset function, because its a bad data.\r\n\r\n\r\nall_trips_v2 <- subset(all_trips, ride_length>0)     #include only ride length over 0 s\r\n\r\n\r\nConduct descriptive analysis\r\nIn order to identify trends and relationships in the data, we can conduct descriptive analysis. Here’s the steps:\r\nFirst, we can summarize the rider behavior based on ride_length column. For example longest & shortest ride and average ride length.\r\n\r\n\r\nmean(all_trips_v2$ride_length)\r\n\r\n[1] 1166.846\r\n\r\nmedian(all_trips_v2$ride_length)\r\n\r\n[1] 617\r\n\r\nmax(all_trips_v2$ride_length)\r\n\r\n[1] 2483235\r\n\r\nmin(all_trips_v2$ride_length)\r\n\r\n[1] 1\r\n\r\nsummary(all_trips_v2$ride_length)\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n      1     349     617    1167    1108 2483235 \r\n\r\nCompare members and casual riders based on average ride length or number of rides.\r\n\r\n\r\nmember_compare <- all_trips_v2 %>%                #call dataset\r\n  drop_na(member_casual) %>%                      #drop empty data\r\n  group_by(membership_type = member_casual) %>%   #group the data by members type\r\n  summarize(average_ride_length = mean(ride_length), number_of_rides = n())  #summarize them with avg and number of rides\r\n\r\nView(member_compare)      #view new data frame\r\n\r\n\r\nDo a comparison of average ride time by each day_of_week column.\r\n\r\n\r\n#Reorder the levels of day_of_week column with Sunday as the first\r\n\r\nall_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"))\r\n\r\n#Summarize them based on day of the week\r\n\r\navg_member_per_day <- all_trips_v2 %>%\r\n  drop_na(member_casual) %>% \r\n  group_by(membership_type = member_casual, day_of_week) %>% \r\n  summarize(average_ride_length = mean(ride_length))\r\n\r\nView(avg_member_per_day)\r\n\r\n\r\nLastly, let’s count the number of rides by members type and day of week using ride_id column.\r\n\r\n\r\n### first check the ride_id duplicate to count number of ride\r\nsum(duplicated(all_trips_v2$ride_id))\r\n\r\n[1] 0\r\n\r\n### if zero, lets goo\r\nmembertype_per_day <- all_trips_v2 %>%\r\n  drop_na(member_casual) %>% \r\n  group_by(membership_type = member_casual, day_of_week) %>% \r\n  summarise(number_of_rides = n(), average_ride_length = mean(ride_length)) %>% #n() for counting \r\n  arrange(day_of_week)\r\n\r\nView(membertype_per_day)\r\n\r\n\r\nDesign a data visualization\r\nFor the next phase, we visualize what has been describe in the analysis process. Here’s the step:\r\nFirst, we can visualize number of rides by membership type. This will helps us to understand which riders have the highest number of rides.\r\n\r\n\r\nggplot(data = membertype_per_day, mapping = aes(x = day_of_week, y = (number_of_rides/1000), fill = membership_type)) + \r\n  geom_col(position = \"dodge\") +\r\n  labs(title = \"Number of Rides by Membership Type in 2022\", \r\n       x = \"\", y = \"Number of Rides<br><span style = 'font-size:8pt'>(in thousand)<\/span>\", \r\n       fill = \"Membership Type\")+\r\n  theme(axis.title.y = ggtext::element_markdown())\r\n\r\n\r\n#save the data viz in .png format\r\nggsave(filename = \"number-of-ride.png\", width = 6.86, height = 4.11, dpi=300)\r\n\r\n\r\nNext, visualize the average duration by members type each day of the week.\r\n\r\n\r\nggplot(data = membertype_per_day, mapping = aes(x = day_of_week, y = average_ride_length, fill = membership_type)) + \r\n  geom_col(position = \"dodge\") +\r\n  labs(title = \"Average Ride Length by Membership Type in 2022\", \r\n       x = \"\", y = \"Average Ride Length<br><span style = 'font-size:8pt'>(in second)<\/span>\", \r\n       fill = \"Membership Type\")+\r\n  theme(axis.title.y = ggtext::element_markdown())\r\n\r\n\r\n#save the data viz in .png format\r\nggsave(filename = \"avg-length.png\", width = 6.86, height = 4.11, dpi=300)\r\n\r\n\r\nTo find a potential days to promote memberships program to casual riders, we need to identify which day with the most number of rides by casual riders.\r\n\r\n\r\n#filter the dataframe by only casual riders\r\nhighest_day_nor <- membertype_per_day %>% \r\n  filter(membership_type == \"casual\") %>% \r\n  arrange(desc(number_of_rides))\r\n\r\n  ggplot(data = highest_day_nor, mapping = aes(x = (number_of_rides/1000), y = (day_of_week = reorder(day_of_week, number_of_rides)))) + \r\n    geom_col() +\r\n    labs(title = \"Number of Rides Per Day by Casual Riders\",\r\n        x = \"Number of Rides<br><span style = 'font-size:8pt'>(in thousand)<\/span>\", y = \"\")+\r\n    theme(axis.title.x = ggtext::element_markdown())\r\n\r\n\r\n#save the graph  \r\nggsave(filename = \"high-nor-day.png\", width = 6.86, height = 4.11, dpi=300)\r\n\r\n\r\nExport a summary file for further analysis\r\nTo export a summary data frame into a csv format, here’s the code\r\n\r\n\r\nwrite.csv(member_compare, file = \"all_member_compare.csv\")\r\nwrite.csv(membertype_per_day, file = \"by_day_member_compare.csv\")\r\n\r\n\r\nAnalysis\r\nThe Cyclistic bikes usage difference by rider type\r\nTo understand each rider behavior of using bikes in 2022, we need to utilize number of rides and ride duration data. This will helps describe how they differ from each other as we can see from Fig. 2.\r\nFig. 2. Casual and members riders difference based on number of rides and ride duration.In Fig. 2, we see a comparison between two types of rider that using Cyclistic bikes. Then compare them based on number of rides and average ride length. We discovered that members riders have a higher number of rides than casual riders. However, casual riders tend to have a longer ride duration (1,749 second) even with less number of rides (2.321 mil).\r\nNumber of rides by day\r\nThis section will explain about how frequently they use Cyclistic bikes during the week. This will assist Cyclistic marketing to determining which day they are most likely to ride. We can see more detail in this Fig. 3.\r\nFig. 3. The number of rides done by each rider during the week.This graph Fig. 3. above illustrates the number of rides done from Sunday to Saturday throughout 2022. Casual riders are represented by the red column, while Cyclistic members are represented by the blue column. From this graph Fig. 3. , we discovered that casual riders maintained a lower number of rides than members from Monday to Friday. On weekends, however, casual riders have a slightly higher number of rides than members. This suggest that casual rider less likely to ride on weekday.\r\nAverage ride length by day\r\nThis section will explain about how longer they ride using Cyclistic bikes during the week. This will assist Cyclistic marketing to determining which day they are most likely to ride longer. We can see more detail in this Fig. 4.\r\nFig. 4. The average ride lengths done by each rider during the week.This graph Fig. 4. above illustrates the average ride length done during the week throughout 2022. From this graph Fig. 4. , we observed that casual riders shown longer ride lengths than members every day. In facts, casual riders have a longer ride on weekday, even with less number of rides than members. This suggest that casual rider more likely to ride longer.\r\nPotential days to promote membership program\r\nIn this section, we observed the number of rides taken by casual riders. This data will help us to determine potential days to promote the membership program to casual riders who are already familiar with Cyclistic. This will also help the company generate more annual members, which will be beneficial. Here is Fig. 5. about number of rides per day by casual rider.\r\nFig. 5. The number of rides per day by casual riders.This graph Fig. 5. above illustrates the number of rides taken by casual riders during the week in 2022. From this graph Fig. 5. , we observed that casual riders show a higher number of ride on weekend. On Saturday, 473 thousand ride are completed. On the other hand, weekdays appear to have fewer rides, ranging from 264 to 334 thousand rides. This suggest that on weekends, there are more casual riders.\r\nWhy casual riders do not convert to members?\r\nIn this section, we create a hypothesis after identifying how casual and members use Cyclistic bikes differently. Here are a few potential causes of why casual riders do not purchase membership programs:\r\nMarketing mismatch\r\nOur first hypothesis is that casual riders do not join the membership program due to a marketing mismatch. So, we need to analyze the Cyclistic marketing strategies in 2022. To realize this, we need more data required such as:\r\nLead generation data (e.g. how did you hear about Cyclistic?)\r\nDigital media/ads performance data\r\nAfter gathering data, we can determine whether there are significantly different methods of discovering Cyclistic for casual riders and members. Then we look at how digital media influences casual riders to become members.\r\nIncentive mismatch\r\nOur second hypothesis is that casual riders are not interested by current membership benefits as they can obtain them as a casual. As a result, we need to investigate the membership plan. To accomplish this, we need to take steps such as:\r\nBreakdown of riders difference by number of rides and ride length\r\nSurvey of “why did you use Cyclistic bikes” – broken out by riders type\r\nAfter breakdown the data we have and conducting a survey, we can understand how casual and member riders use the bikes differently. As a result, we understand why the use of Cyclistic bikes varies by rider type.\r\nRecommendation\r\nAfter conducting a descriptive analysis to identify how different riders use Cyclistic, our strategies to increase annual membership as follow:\r\nDefine new membership program main benefits\r\nAs we learn before, casual riders have a longer ride duration. We can then design pricing plans based on limiting the ride duration. So, more people have the urge to be Cyclistic members with unlimited duration benefits.\r\nCreate new pricing plans based on ride length for casual riders\r\nBased on casual riders longer ride length, we can create new pricing plans using The Decoy Effect strategies. For casual, make the pricing plans based on limited ride duration. This will make the membership plan more profitable.\r\nDesign a marketing strategies that highlight new membership benefits\r\nFollowing the establishment of pricing plans, we can plan the marketing strategy on a day with higher number of rides by casual riders (Saturday and Sunday). Highlight the main benefits of members in a targeted manners.\r\nTest and learn\r\nRun the program on weekly basis to evaluate which pricing plans are working and which aren’t. Create a KPI’s to define a successful program (e.g. new members growth, number of rides by casual, day of the week, etc.)\r\nAppendix\r\nPresentable data analysis → PPT\r\nData Analysis Process in R scripts → R Code\r\nGoogle Data Analytics Coursera\r\n\r\n\r\n\r\n",
    "preview": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/image1_hH9B4gs.jpg",
    "last_modified": "2023-02-15T11:02:33+07:00",
    "input_file": "bike-share-analysis-using-r.knit.md"
  },
  {
    "path": "posts/2022-12-20-world-co2-emissions-growth-using-tableau/",
    "title": "World CO₂ Emissions Growth with Dashboard using Tableau",
    "description": "A guide to create an effective and clear dashboard for better understand average CO₂ in the world using CO₂ dataset.",
    "author": [
      {
        "name": "Miftahul Hadi",
        "url": {}
      }
    ],
    "date": "2022-12-20",
    "categories": [
      "Tableau",
      "Data Visualization"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nPreparation\r\nCreate a Dashboard\r\nAnalysis\r\nConclusion\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nAccording to the World Meteorological Organization’s (WMO), the past eight years are the warmest Earth temperature on record. To better understand about this climate changes, I want to design a dashboard about World CO₂ Emissions Growth. This dashboard will review the average CO₂ that produced in every country. Then, we try to investigate the production growth over the year in every region. Hopefully, this dashboard will be beneficial to reduces and mitigates the effects of global climate changes.\r\nFig. 1. The spreading of factory residueHere, we used the data sets from The World Bank Group, a world organization that work to reduce poverty in a country. This data sets include several variable such as:\r\nCountry Name\r\nYear of CO₂ collected\r\nCO₂ per Capita.\r\nWhat to analyze?\r\nThis data set can be used to find a questions that might arise such as:\r\nWhich country/region has the most average CO₂ per capita?\r\nWhat region has the highest growth of CO₂ emitters?\r\nHopefully, this questions will be a step to reveal what inside the data sets and helps other countries to mitigate the global climate changes.\r\nPreparation\r\nHere, I want to describe a few tools used in this analysis:\r\nTableau Public\r\nExcel (for storing data)\r\nCO₂ Dataset\r\nCreate a Dashboard\r\nHere’s a step-by-step to create a clear dashboard about CO₂ growth. You can click every step to show the detailed :\r\nLoad the Dataset\r\nTo connect the dataset to Tableau, the step as follows:\r\nFirst, open Tableau Public application.\r\nThen, the first window you see might be like this.\r\n\r\n\r\n\r\nSelect Microsoft Excel (because our dataset is in excel format), then locate to the dataset file.\r\nNext, a lot of sheet inside of dataset will appear. This is Data Source window.\r\n\r\n\r\n\r\nConnect the Tableau to useful sheet that already been cleaned. Here, we choose CO2 Data Cleaned because the sheet involves metrics needed.\r\nLast, we can go to worksheet\r\n\r\n\r\n\r\nAs a preview, here is a view of Tableau project we work on.\r\n\r\n\r\n\r\nAs the image above, there are three sections that show up, including:\r\nLeft-side = Where the data stored.\r\nMiddle = Tools to refine your data visualization.\r\nRight-side = Place to view your visualization.\r\nCreate a Graph\r\nIn this section, we want plotting the dataset about CO₂ activity in the World to answers question.\r\nAverage CO₂ per Capita\r\nHere’s the step to create a clear graph of average CO₂ for every country:\r\nFirst, we put the Country Name column to Detail in Marks pane.\r\n\r\n\r\n\r\nA map will appear with the country as a data points.\r\n\r\n\r\n\r\nThen, we calculate the average CO₂ per Capita for every country by drag the CO2 Per Capita (metric tons) column to Size in Marks pane.\r\n\r\n\r\n\r\nAverage of CO₂ per Capita will appear with circle size. The larger the circle, the highest average.\r\n\r\n\r\n\r\nThen, we can add a color divergence on the circle to make the average CO₂ per capita more clear.\r\n\r\n\r\n\r\nThen, we can see the divergence of color in the circle. The higher the blue concentrate, higher the average.\r\n\r\n\r\n\r\nTo make it more clear, we can change the color from Blue to Red-Green.\r\nClick Edit Colors, make the colors reversed, because green indicate low CO₂ and red for high CO₂. Make the center to 4.\r\n\r\n\r\n\r\nMake the size of the circle correlated to average CO₂ per Capita.\r\n\r\n\r\n\r\nAdd a border color on circle.\r\n\r\n\r\n\r\nChange the title and this is the first graph for Average CO₂ per Capita.\r\n\r\n\r\n\r\nCO₂ Production by Region\r\nHere’s the step to a viz about CO₂ production over the years:\r\nFirst, add a new worksheet for different graph.\r\n\r\n\r\n\r\nAdd Region column on color marks.\r\n\r\n\r\n\r\nThen, add Year as a columns & CO2 (kt) as a rows.\r\n\r\n\r\n\r\nHere’s the graph. You see that the year is too crowded.\r\n\r\n\r\n\r\nMake it only per 10 years by ranges.\r\n\r\n\r\n\r\nThere you go. Here the graph explain about CO₂ production by Region\r\n\r\n\r\n\r\nNext, we can combine this two graph to design a clear dashboard.\r\nDesign the dashboard\r\nIn this section, we want to combine two graph we have created into one dashboard. Here’s the step:\r\nFirst, create a new dashboard.\r\n\r\n\r\n\r\nLet’s add two graph we’ve created before by dragging the sheet into canvas.\r\n\r\n\r\n\r\nAfter dragging two graph. Then, it will looks like this.\r\n\r\n\r\n\r\nNotice that the legend is kind of confusing. Let’s move it into the relevant graph.\r\nTo move the legend, first click More options, then choose Floating.\r\n\r\n\r\n\r\nDo this with color divergence legend. Delete the circle legend.\r\nThen, remove the unused container to make the dashboard more clear.\r\n\r\n\r\n\r\nFinal dashboard\r\nHere’s the final dashboard that we have created.\r\n\r\n\r\n\r\nNow, the legend is tied with each graph. It’s give a context to graph and make the dashboard more clear.\r\nAnalysis\r\nAverage CO₂ per capita\r\n\r\n\r\n\r\nThis graph describes the average of CO₂ per capita in every country, between 1960 and 2011. The circle shows where the country is. Darker red or bigger circles indicate the country produces more CO₂ than the others. Darker the green or smaller circles, the less CO₂ to be produced.\r\nFrom the graph above, we can see that the Middle-east country has the highest average CO₂ per capita. For example, Qatar (one of the Middle-east countries) has an average of 54.42 tons per capita. It means that Qatari people have produced more CO₂ than any other country in the world. This is because of Qatar’s heavy reliance on gas and oil and has relatively small population when compared to other countries. This make the average larger. There’s also UAE (31.84 tons), Kuwait (28.4 tons), Bahrain (19.87 tons), and others.\r\nOn the opposite, most of Africa and South America country has the lowest average CO₂ per capita. Chad (one of the African countries) has the average of 0.03 tons per capita, the lowest in the world.\r\nGrowth of CO₂ emitters\r\n\r\n\r\n\r\nThis graph describes the CO₂ production growth in a number of regions between 1960 and 2011. Here, the CO₂ production is measured by kilo ton (kt). Each region shows in a colored line.\r\nFrom the graph above, each region tend to produce more CO₂ every year. In 1960, the highest CO₂ emitter is North America region. But 50 years later, East Asia & Pacific has produces more CO₂ than any others region.\r\n\r\n\r\n\r\nIn the graph above, we can see the rapid increase of CO₂ production in East Asia & Pacific from 1960 to 2011. In 1960, the CO₂ production is about 1,17 billion tons. 40 years later, the production is increased by 6 times (6,34 billion tons). It took only 10 years later to get 12,74 billion tons. This indicates that the increase rate of CO₂ production in East Asia & Pacific is significant.\r\nConclusion\r\nAccording to this analysis, we find that Qatar’s reliance on Gas and Oil makes the country the highest average of CO₂ per capita with 54.42 tons produced. But, the growth of CO₂ production in East Asia & Pacific should be wary with only 10 years from 2000, the CO₂ production increased 2 times higher by 12,74 billion tons.\r\nSuggestion\r\nFor the next analysis, a population dataset is needed for better little-bias analysis. Because, Qatar with less population could get a higher average of CO₂ per capita than other countries with a higher population.\r\nSource\r\nDeardorff, A., 2016. Tableau (version. 9.1). Journal of the Medical Library Association, 104(2), pp.182-183.\r\nSheikh, S. E. (2022) ‘Eight warmest years on record witness upsurge in climate change impacts’, World Meteorological Organization, 6 Nov. Available at: https://public.wmo.int/en/media/press-release/eight-warmest-years-record-witness-upsurge-climate-change-impacts\r\nHamilton, K. (2017) ‘Economic co-benefits of reducing CO2 emissions outweigh the cost of mitigation for most big emitters’, The London School of Economics and Political Science, 3 Nov. Available at: https://www.lse.ac.uk/granthaminstitute/news/economic-co-benefits-of-reducing-co2-emissions-outweigh-the-cost-of-mitigation-for-most-big-emitters/\r\nClimate Watch Org. (2020) ‘CO2 emissions (metric tons per capita)’. Available at: http://data.worldbank.org/indicator/EN.ATM.CO2E.PC\r\nAdema, S. (2022) ‘Understanding Qatar’s Ecological Footprint’, Ecomena, 1 March. Available at: https://www.ecomena.org/qatar-ecological-footprint/\r\nAl-Asmakh, M. and Al-Awainati, N., 2018, March. Counting the Carbon: Assessing Qatar’s Carbon Dioxide Emissions. In Qatar Foundation Annual Research Conference Proceedings Volume 2018 Issue 1 (Vol. 2018, No. 1, p. EEPD592). Hamad bin Khalifa University Press (HBKU Press).\r\n\r\n\r\n\r\n",
    "preview": "https://i.ytimg.com/vi/9OX9ohTcC1w/maxresdefault.jpg",
    "last_modified": "2023-02-06T20:51:32+07:00",
    "input_file": "world-co2-emissions-growth-using-tableau.knit.md"
  },
  {
    "path": "posts/2022-12-13-fitness-trackers-e-commerce-in-indian-market/",
    "title": "Fitness Trackers e-Commerce in Indian Market",
    "description": "A financial analysis about fitness trackers device sales in Indian market on 2022.",
    "author": [
      {
        "name": "Miftahul Hadi",
        "url": {}
      }
    ],
    "date": "2022-12-06",
    "categories": [
      "R",
      "Financial Analysis",
      "Data Visualization"
    ],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nPreparation\r\nAnalysis\r\nConclusion\r\nSuggestion\r\nSource\r\n\r\nIntroduction\r\nIn this activity, I want to analyze a Fitness Trackers Device product from various brands. This report will analyze review about the device in Indian market. After that, we try to investigate the material used in the device including strap material, battery, and the price itself.\r\nFig. 1. Fitness Tracker DeviceHere, we used the data sets from Flipkart, one of an e-commerce website. This data sets include several variable such as:\r\nSelling Price\r\nSpecifications\r\nRatings\r\nReview from the Indian Market\r\nThis data has been collected using Kaggle in this link\r\nWhat to analyze?\r\nThis data set can be used to find a questions that might arise such as:\r\nWhat is the best strap material for Fitness Tracker Device?\r\nIs more battery life necessary for Smartwatches or Fitness Band?\r\nWhat is the mean price for selling a fitness tracker that might get at least 4.0 ratings?\r\nHopefully, this questions will reveal what inside the data sets and help other company to strategies the India Market.\r\nPreparation\r\nHere, I want to describe a few tools in this analysis:\r\nRStudio\r\nLibrary including:\r\ntidyverse\r\nggplot2\r\ndplyr\r\nreadr\r\nskimr\r\n\r\nDataset link\r\nBefore doing our analysis, we loaded the library.\r\n\r\n\r\nShow code\r\n\r\nlibrary(tidyverse)\r\nlibrary(ggplot2)\r\nlibrary(dplyr)\r\nlibrary(readr)\r\nlibrary(skimr)\r\nlibrary(formattable)\r\nlibrary(ggpubr)\r\n\r\n\r\nThen, load and name the dataset as a fitness_tracker using readr library.\r\n\r\n\r\nShow code\r\n\r\nlibrary(readr)\r\n\r\n#Use your file location\r\nfitness_trackers <- read_csv(\"D:/Bahan Belajar/Experience/Sertifikasi LinkedIn/Project/1_R_Fitness Tracker_ecommerce/Fitness_trackers.csv\")\r\n\r\n\r\nLast, we want to get better understanding of our data using glimpse() & skim_without_charts() to check the null value.\r\n\r\n\r\nshow\r\n\r\nglimpse(fitness_trackers)\r\n\r\nRows: 565\r\nColumns: 11\r\n$ `Brand Name`                     <chr> \"Xiaomi\", \"Xiaomi\", \"Xiaomi…\r\n$ `Device Type`                    <chr> \"FitnessBand\", \"FitnessBand…\r\n$ `Model Name`                     <chr> \"Smart Band 5\", \"Smart Band…\r\n$ Color                            <chr> \"Black\", \"Black\", \"Black\", …\r\n$ `Selling Price`                  <dbl> 2499, 2099, 1722, 2469, 179…\r\n$ `Original Price`                 <dbl> 2999, 2499, 2099, 2999, 219…\r\n$ Display                          <chr> \"AMOLED Display\", \"AMOLED D…\r\n$ `Rating (Out of 5)`              <dbl> 4.1, 4.2, 3.5, 4.1, 4.3, 4.…\r\n$ `Strap Material`                 <chr> \"Thermoplastic polyurethane…\r\n$ `Average Battery Life (in days)` <dbl> 14, 14, 14, 14, 7, 20, 7, 1…\r\n$ Reviews                          <dbl> NA, NA, NA, NA, NA, NA, NA,…\r\n\r\nshow\r\n\r\nskim_without_charts(fitness_trackers)\r\n\r\n(#tab:Understand the data)Data summary\r\nName\r\nfitness_trackers\r\nNumber of rows\r\n565\r\nNumber of columns\r\n11\r\n_______________________\r\n\r\nColumn type frequency:\r\n\r\ncharacter\r\n6\r\nnumeric\r\n5\r\n________________________\r\n\r\nGroup variables\r\nNone\r\nVariable type: character\r\nskim_variable\r\nn_missing\r\ncomplete_rate\r\nmin\r\nmax\r\nempty\r\nn_unique\r\nwhitespace\r\nBrand Name\r\n0\r\n1\r\n4\r\n8\r\n0\r\n19\r\n0\r\nDevice Type\r\n0\r\n1\r\n10\r\n11\r\n0\r\n2\r\n0\r\nModel Name\r\n0\r\n1\r\n1\r\n62\r\n0\r\n384\r\n0\r\nColor\r\n0\r\n1\r\n3\r\n44\r\n0\r\n134\r\n0\r\nDisplay\r\n0\r\n1\r\n11\r\n19\r\n0\r\n7\r\n0\r\nStrap Material\r\n0\r\n1\r\n5\r\n26\r\n0\r\n11\r\n0\r\nVariable type: numeric\r\nskim_variable\r\nn_missing\r\ncomplete_rate\r\nmean\r\nsd\r\np0\r\np25\r\np50\r\np75\r\np100\r\nSelling Price\r\n0\r\n1.00\r\n22110.37\r\n19914.93\r\n1195\r\n8990.00\r\n15995.0\r\n29900.00\r\n122090\r\nOriginal Price\r\n0\r\n1.00\r\n25365.36\r\n20384.03\r\n1599\r\n12999.00\r\n19995.0\r\n32900.00\r\n122090\r\nRating (Out of 5)\r\n51\r\n0.91\r\n4.23\r\n0.39\r\n2\r\n4.03\r\n4.3\r\n4.50\r\n5\r\nAverage Battery Life (in days)\r\n0\r\n1.00\r\n9.03\r\n7.87\r\n1\r\n2.00\r\n7.0\r\n14.00\r\n45\r\nReviews\r\n487\r\n0.14\r\n2492.95\r\n5607.53\r\n2\r\n107.75\r\n346.0\r\n1580.75\r\n23426\r\n\r\nAnalysis\r\nThe best strap material for Fitness Tracker Device?\r\nFitness Band Material\r\nHere, we try to find which strap material for Fitness Band is having a high average rating. The rating is obtained by calculating the average rating per strap material. Then do the ranking analysis.\r\n\r\n\r\nShow code\r\n\r\n#Fitness Band\r\n#Calculate the average rating by strap material\r\nmean_strap_fitnessband <- fitness_trackers %>% \r\n  group_by(`Strap Material`) %>%\r\n  filter (`Device Type` == \"FitnessBand\") %>% \r\n  summarize(avg_rating = mean(`Rating (Out of 5)`))\r\n\r\n#Plot the average rating with strap material\r\nggplot(data = mean_strap_fitnessband, \r\n       mapping = aes(x = avg_rating, y = reorder(`Strap Material`, avg_rating), alpha = avg_rating)) + \r\n  geom_bar(stat = \"identity\", fill = \"black\") + \r\n  geom_text(aes(label = round(avg_rating, digits = 2), fontface = \"bold\"), nudge_x = +0.2, colour = \"black\") +\r\n  labs(title = \"Rating for Fitness Band Material\", subtitle = \"based on Review in Indian Market\", x = \"Average Rating\", y = \"Strap Material\", alpha = \"Range of Rating\")\r\n\r\n\r\n\r\nFrom the bar chart above, we see the brand name on the left-axis with their average rating. Elastomer is getting highest rating in Indian market by 4.22. Then follow tightly by Plastic. The use of leather is less preferable for Fitness Band in Indian market.\r\nSmartwatch Material\r\nHere, we try to find which strap material for Smartwatch is having a high average rating. The rating is obtained by calculating the average rating per strap material. Then do the ranking analysis.\r\n\r\n\r\nShow code\r\n\r\n#Smartwatches\r\n#Calculate the average rating by strap material\r\nmean_strap_smartwatch <- fitness_trackers %>% \r\n  drop_na() %>% \r\n  group_by(`Strap Material`) %>%\r\n  filter (`Device Type` == \"Smartwatch\") %>% \r\n  summarize(avg_rating = mean(`Rating (Out of 5)`))\r\n\r\n#Plot the average rating with strap material\r\nggplot(data = mean_strap_smartwatch, \r\n       mapping = aes(x = avg_rating, y = reorder(`Strap Material`, avg_rating), alpha = avg_rating)) + \r\n  geom_bar(stat = \"identity\", fill = \"black\") + \r\n  geom_text(aes(label = round(avg_rating, digits = 2), fontface = \"bold\"), nudge_x = +0.2, colour = \"black\") +\r\n  labs(title = \"Rating for Smartwatch Material\", subtitle = \"based on Review in Indian Market\", x = \"Average Rating\", y = \"Strap Material\", alpha = \"Range of Rating\")\r\n\r\n\r\n\r\nFrom the bar chart above, we see that Nylon is getting highest rating in Indian market by 4.4. Then follow tightly by Silicone. The use of rubber is less preferable for smart watches in Indian market.\r\nIs more battery life necessary for Smartwatches or Fitness Band?\r\nHere, we want to inspect whether or not if more battery life is an important factor for having a high rating in Indian Market. To do that:\r\nTake the Battery Life and Rating Column.\r\nThen, show the relationship between them using scatter plot.\r\nHere’s the formula in R\r\n\r\n\r\nShow code\r\n\r\n#Plot the battery life with rating\r\nggplot(data = fitness_trackers, \r\n       mapping = aes(x = `Average Battery Life (in days)`, y = `Rating (Out of 5)`, alpha = `Rating (Out of 5)`)) + \r\n  geom_smooth() +\r\n  stat_cor(method = \"pearson\", label.x = -5, label.y = 4.8) +\r\n  facet_wrap(~`Device Type`) +\r\n  labs(title = \"Relationship between Battery Life vs. Rating\", subtitle = \"based on Review in Indian Market\", \r\n       x = \"Average Battery Life (in days)\", y = \"Rating\")\r\n\r\n\r\n\r\nFrom the scatter plot above, we see the average battery life (in days) on the x-axis with their rating on y-axis. Scatter plot is used to reveal a correlation between two or more variables. Correlation coefficient is used to show whether strong or not the correlation is. If R is positive and near 1, then battery life is dependent to rating.\r\nIn Fitness Band on the left, we see that there is no strong linear correlation between battery life and rating. The R on Fitness band is 0.12. It shows that little correlation between them. Rating above 4.00 is actually obtained in battery life that has at least 5 to 20 days.\r\nIn Smartwatch on the right, we see that the R on Fitness band is -0.18. It shows a little negative linear correlation. Less battery life and is sometimes get a high rating. Higher rating with above 4.5 is obtained on battery life below 5 days.\r\nMean price for selling a fitness tracker\r\nHere, we want to inspect the mean price for selling a fitness tracker in Indian Market. We want the mean price will get at least 4.0 rating. To do that:\r\nTake the Selling Price and Rating Column.\r\nThen, show the relationship between them using scatter plot.\r\nLastly, check the mean selling price that will get at least 4.0 rating.\r\nHere’s the formula in R to check the correlation for selling price in Smartwatch.\r\n\r\n\r\nShow code\r\n\r\n#Smartwatches\r\n#Calculate the mean selling prices\r\nmean_selling_smartwatch <- fitness_trackers %>% \r\n  group_by(`Rating (Out of 5)`) %>%\r\n  filter (`Device Type` == \"Smartwatch\") %>% \r\n  summarize(selling_price = mean(`Selling Price`))\r\n\r\n#Plot the average selling price with device rating\r\nggplot(data = mean_selling_smartwatch, \r\n       mapping = aes(x = `Rating (Out of 5)`, y = selling_price)) + \r\n  geom_smooth() + \r\n  stat_cor(method = \"pearson\") +\r\n  labs(title = \"Rating by Selling Price\", subtitle = \"on Smartwatch\", x = \"Device Rating\", y = \"Selling Price\")\r\n\r\n\r\n\r\nIf we see the chart above, the R value for Smartwatch’s selling price is low. So we unable to measure the mean selling price for getting higher rating, because little correlation between them.\r\nLet’s check the selling price in Fitness Band.\r\n\r\n\r\nShow code\r\n\r\n#Fitness band\r\n#Calculate the mean selling prices\r\nmean_selling_fitnessband <- fitness_trackers %>% \r\n  group_by(`Rating (Out of 5)`) %>%\r\n  filter (`Device Type` == \"FitnessBand\") %>% \r\n  summarize(selling_price = mean(`Selling Price`))\r\n\r\n#Plot the average selling price with device rating\r\nggplot(data = mean_selling_fitnessband, \r\n       mapping = aes(x = `Rating (Out of 5)`, y = selling_price)) + \r\n  geom_smooth() + \r\n  stat_cor(method = \"pearson\") +\r\n  labs(title = \"Rating by Selling Price\", subtitle = \"on Fitness Band\", x = \"Device Rating\", y = \"Selling Price\")+\r\n  annotate(\"text\", x = 4, y = 7000, label = \"The mean price to get more than 4.0 rating is ₹5,000\", fontface = \"bold\", angle = 25)+\r\n  annotate(\"segment\", x = 4, y = 2500, xend = 4, yend = 4900, arrow = arrow(type = \"closed\", length = unit(0.02, \"npc\")))\r\n\r\n\r\n\r\nWhen we see the R, the correlation between selling price and rating on Fitness Band is strong (0.76 out of 1). So, we can measure the mean price to get more than 4.0 rating.\r\nNext, the mean price to get more than 4.0 rating is ₹5,000. If the selling price is increasing, the rating tend to be higher. Then the specifications price is needed to see further analysis on selling prices.\r\nConclusion\r\nAfter doing an analysis about fitness tracker in Indian market on 2022, we can conclude that:\r\nStrap material for different device require different material. Elastomer is preferable for Fitness Band. But for Smartwatches, the use of Nylon is getting highest rating.\r\nMore battery life on fitness tracker device is not necessary to get higher rating.\r\nThe preferable selling price for Fitness Band is ₹ 5,000. For Smartwatches, the selling price unable to be measured because no correlation with ratings.\r\nSuggestion\r\nFor further analysis, the specifications price is needed. This is important to measure a material with the lowest price but getting highest ratings.\r\nSource\r\nRStudio\r\nFitness Tracker Dataset: Kaggle\r\n\r\n\r\n\r\n",
    "preview": "https://phoneradar.com/wp-content/uploads/2014/09/GetActive-Tapp.jpg",
    "last_modified": "2023-01-03T12:56:32+07:00",
    "input_file": {}
  }
]
